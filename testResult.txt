CnnBiLSTM1D(
  (tanh): Tanh()
  (relu): ReLU()
  (dropout_): Dropout(p=0.005, inplace=False)
  (softmax): Softmax(dim=1)
  (block_1): InitConv(
    (relu): ReLU()
    (dropout_): Dropout(p=0.005, inplace=False)
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (tanh): Tanh()
    (softmax): Softmax(dim=1)
    (conv1d_1): Conv1d(1, 4, kernel_size=(5,), stride=(2,))
    (batch_norm_1d_1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv1d_2): Conv1d(4, 16, kernel_size=(4,), stride=(2,))
    (batch_norm_1d_2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv1d_3): Conv1d(16, 32, kernel_size=(4,), stride=(2,))
    (batch_norm_1d_3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv1d_4): Conv1d(32, 32, kernel_size=(4,), stride=(2,))
    (batch_norm_1d_4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (linear_1d_1): Linear(in_features=7136, out_features=2048, bias=True)
    (linear_1d_2): Linear(in_features=2048, out_features=1024, bias=True)
    (linear_1d_3): Linear(in_features=1024, out_features=512, bias=True)
    (linear_1d_4): Linear(in_features=512, out_features=256, bias=True)
    (attention_linear_1d_1): Linear(in_features=256, out_features=256, bias=True)
  )
  (block_2): InitConv(
    (relu): ReLU()
    (dropout_): Dropout(p=0.005, inplace=False)
    (flatten): Flatten(start_dim=1, end_dim=-1)
    (tanh): Tanh()
    (softmax): Softmax(dim=1)
    (conv1d_1): Conv1d(1, 4, kernel_size=(5,), stride=(2,))
    (batch_norm_1d_1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv1d_2): Conv1d(4, 16, kernel_size=(4,), stride=(2,))
    (batch_norm_1d_2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv1d_3): Conv1d(16, 32, kernel_size=(4,), stride=(2,))
    (batch_norm_1d_3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv1d_4): Conv1d(32, 32, kernel_size=(4,), stride=(2,))
    (batch_norm_1d_4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (linear_1d_1): Linear(in_features=7136, out_features=2048, bias=True)
    (linear_1d_2): Linear(in_features=2048, out_features=1024, bias=True)
    (linear_1d_3): Linear(in_features=1024, out_features=512, bias=True)
    (linear_1d_4): Linear(in_features=512, out_features=256, bias=True)
    (attention_linear_1d_1): Linear(in_features=256, out_features=256, bias=True)
  )
  (bilinear): Bilinear(in1_features=256, in2_features=256, out_features=256, bias=True)
  (linear_1): Linear(in_features=1024, out_features=512, bias=True)
  (linear_2): Linear(in_features=512, out_features=256, bias=True)
  (linear_3): Linear(in_features=256, out_features=128, bias=True)
  (linear_4): Linear(in_features=128, out_features=64, bias=True)
  (out): Linear(in_features=64, out_features=17, bias=True)
  (conv_1d_1): Conv1d(1, 8, kernel_size=(4,), stride=(2,))
  (batch_norm_1d_1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bi_lstm_1): LSTM(256, 512, num_layers=2, dropout=0.005, bidirectional=True)
  (bi_lstm_2): LSTM(1024, 1024, num_layers=2, dropout=0.002, bidirectional=True)
)
Test Loss: 0.102077

Test Accuracy of     0: 100.000000% (52/52)
Test Accuracy of     1: 100.000000% (51/51)
Test Accuracy of     2: 92.307692% (36/39)
Test Accuracy of     3: 94.642857% (53/56)
Test Accuracy of     4: 100.000000% (62/62)
Test Accuracy of     5: 96.296296% (52/54)
Test Accuracy of     6: 91.836735% (45/49)
Test Accuracy of     7: 98.360656% (60/61)
Test Accuracy of     8: 100.000000% (61/61)
Test Accuracy of     9: 98.000000% (49/50)
Test Accuracy of    10: 98.305085% (58/59)
Test Accuracy of    11: 100.000000% (59/59)
Test Accuracy of    12: 100.000000% (44/44)
Test Accuracy of    13: 100.000000% (47/47)
Test Accuracy of    14: 98.039216% (50/51)
Test Accuracy of    15: 98.214286% (55/56)
Test Accuracy of    16: 98.437500% (63/64)

Test Accuracy (Overall): 98.032787% (897/915)
