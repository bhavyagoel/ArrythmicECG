{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.transforms import Compose, Normalize\n",
    "from scipy.ndimage.interpolation import shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6 WPW 273\n",
      "1 5 SVTA 273\n",
      "2 2 APB 264\n",
      "3 15 RBBBB 248\n",
      "4 11 IVR 280\n",
      "5 4 AFIB 270\n",
      "6 7 PVC 266\n",
      "7 1 NSR 283\n",
      "8 13 Fusion 275\n",
      "9 9 Trigeminy 273\n",
      "10 3 AFL 280\n",
      "11 12 VFL 280\n",
      "12 14 LBBBB 206\n",
      "13 16 SDHB 280\n",
      "14 8 Bigeminy 275\n",
      "15 17 PR 270\n",
      "16 10 VT 280\n",
      "4576\n",
      "58\n",
      "15\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "def mat_reader(path_file, square):\n",
    "    ecg = scipy.io.loadmat(path_file)\n",
    "    ecg = {k: v for k, v in ecg.items() if k[0] != '_'}\n",
    "    if square:\n",
    "        return (ecg['val']).reshape(1, 60, 60)\n",
    "    else:\n",
    "        return (ecg['val']).reshape(1, 3600)\n",
    "\n",
    "\n",
    "def x_y_data(data):\n",
    "    np.random.shuffle(data)\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    y = []\n",
    "    x = []\n",
    "    for i in range(len(data)):\n",
    "        k = data[i][0]\n",
    "        y.append(k)\n",
    "        m = data[i][1]\n",
    "        x.append(torch.tensor(m).to(device))\n",
    "    # print(y)\n",
    "    y = torch.tensor(y).type(torch.cuda.LongTensor)\n",
    "    x = torch.stack(x)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "def data_loader(path_dir):\n",
    "    data = []\n",
    "\n",
    "    for _class, _cname in enumerate(os.listdir(path_dir)):\n",
    "        frags_dir = os.path.join(path_dir, _cname)\n",
    "        count = 0\n",
    "        for _frags in os.listdir(frags_dir):\n",
    "            frags_loc = os.path.join(frags_dir, _frags)\n",
    "            x = mat_reader(frags_loc, False)\n",
    "            y = _class\n",
    "            count += 1\n",
    "            data.append([x,y])\n",
    "\n",
    "        if len(os.listdir(frags_dir)) < 284:\n",
    "            inc_count = 284 - len(os.listdir(frags_dir))\n",
    "            \n",
    "            each_file = int(inc_count / len(os.listdir(frags_dir)))\n",
    "            for _frags in os.listdir(frags_dir):\n",
    "                for i in range(each_file):\n",
    "                    count+=1\n",
    "                    if i % 2 == 0:\n",
    "                        alpha = np.copy(x)\n",
    "                        alpha = np.roll(alpha, 2*i)\n",
    "                        y = _class\n",
    "                        data.append([alpha,y])\n",
    "                    else:\n",
    "                        alpha = np.copy(x)\n",
    "                        alpha = np.roll(alpha, -2*i)\n",
    "                        y = _class\n",
    "                        data.append([alpha,y])\n",
    "            print(_class, _cname, count)\n",
    "\n",
    "    x, y = x_y_data(data)\n",
    "    print(len(data))\n",
    "    del data\n",
    "    \n",
    "    num_train = len(x)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(0.2 * num_train))\n",
    "\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    valid_idx, test_idx, train_idx = indices[:split], indices[split:2 * split], indices[split:]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "    train_loader = DataLoader(TensorDataset(x, y), batch_size=64, sampler=train_sampler)\n",
    "    valid_loader = DataLoader(TensorDataset(x, y), batch_size=64, sampler=valid_sampler)\n",
    "    test_loader = DataLoader(TensorDataset(x, y), batch_size=64, sampler=test_sampler)\n",
    "\n",
    "    return train_loader, test_loader, valid_loader\n",
    "\n",
    "\n",
    "class InitConv(nn.Module):\n",
    "    def __init__(self, input_size, dropout, shape):  # 0  for linear, 1 for square\n",
    "        super(InitConv, self).__init__()\n",
    "        self.shape = shape\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout_ = nn.Dropout(p=dropout)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        if self.shape == 0:\n",
    "\n",
    "            # Initial Convolution Model\n",
    "            self.conv1d_1 = nn.Conv1d(in_channels=1, out_channels=4, kernel_size=5, stride=2, bias=True)\n",
    "            self.batch_norm_1d_1 = nn.BatchNorm1d(num_features=4, eps=0.00001, momentum=0.1)\n",
    "\n",
    "            self.conv1d_2 = nn.Conv1d(in_channels=4, out_channels=16, kernel_size=4, stride=2, bias=True)\n",
    "            self.batch_norm_1d_2 = nn.BatchNorm1d(num_features=16, eps=0.00001, momentum=0.1)\n",
    "\n",
    "            self.conv1d_3 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=4, stride=2, bias=True)\n",
    "            self.batch_norm_1d_3 = nn.BatchNorm1d(num_features=32, eps=0.00001, momentum=0.1)\n",
    "\n",
    "            self.conv1d_4 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=4, stride=2, bias=True)\n",
    "            self.batch_norm_1d_4 = nn.BatchNorm1d(num_features=32, eps=0.00001, momentum=0.1)\n",
    "\n",
    "            self.linear_1d_1 = nn.Linear(in_features=7136, out_features=2048)\n",
    "            self.linear_1d_2 = nn.Linear(in_features=2048, out_features=1024)\n",
    "            self.linear_1d_3 = nn.Linear(in_features=1024, out_features=512)\n",
    "            self.linear_1d_4 = nn.Linear(in_features=512, out_features=256)\n",
    "\n",
    "            # Attention Model\n",
    "            self.attention_linear_1d_1 = nn.Linear(in_features=256, out_features=256, bias=True)\n",
    "\n",
    "        elif self.shape == 1:\n",
    "            self.conv2d_1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=(2, 2), stride=(2, 2), bias=True)\n",
    "            self.batch_norm_2d_1 = nn.BatchNorm2d(num_features=4, eps=0.00001, momentum=0.1)\n",
    "\n",
    "            self.conv2d_2 = nn.Conv2d(in_channels=4, out_channels=16, kernel_size=(2, 2), stride=(1, 2), padding=(2, 2),\n",
    "                                      padding_mode=\"reflect\")\n",
    "            self.batch_norm_2d_2 = nn.BatchNorm2d(num_features=16, eps=0.00001, momentum=0.1)\n",
    "\n",
    "            self.conv2d_3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(2, 2), stride=(2, 1),\n",
    "                                      padding=(2, 2), padding_mode=\"reflect\")\n",
    "            self.batch_norm_2d_3 = nn.BatchNorm2d(num_features=32, eps=0.00001, momentum=0.1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if self.shape == 0:\n",
    "            t = inputs\n",
    "            t = self.conv1d_1(t)\n",
    "            t = self.batch_norm_1d_1(t)\n",
    "            t = self.relu(t)\n",
    "            t = self.dropout_(t)\n",
    "\n",
    "            t = self.conv1d_2(t)\n",
    "            t = self.batch_norm_1d_2(t)\n",
    "            t = self.relu(t)\n",
    "            t = self.dropout_(t)\n",
    "\n",
    "            t = self.conv1d_3(t)\n",
    "            t = self.batch_norm_1d_3(t)\n",
    "            t = self.relu(t)\n",
    "            t = self.dropout_(t)\n",
    "\n",
    "            t = self.conv1d_4(t)\n",
    "            t = self.batch_norm_1d_4(t)\n",
    "            t = self.relu(t)\n",
    "            t = self.dropout_(t)\n",
    "\n",
    "            t = self.flatten(t)\n",
    "\n",
    "            t = self.linear_1d_1(t)\n",
    "            t = self.relu(t)\n",
    "            t = self.dropout_(t)\n",
    "\n",
    "            t = self.linear_1d_2(t)\n",
    "            t = self.relu(t)\n",
    "            t = self.dropout_(t)\n",
    "\n",
    "            t = self.linear_1d_3(t)\n",
    "            t = self.relu(t)\n",
    "            t = self.dropout_(t)\n",
    "\n",
    "            t = self.linear_1d_4(t)\n",
    "\n",
    "            t = self.dropout_(t)\n",
    "\n",
    "            alpha = t.detach().clone()\n",
    "\n",
    "            alpha = self.tanh(alpha)\n",
    "            alpha = alpha.view(alpha.shape[0], 1, alpha.shape[1])\n",
    "\n",
    "            beta = self.attention_linear_1d_1(alpha)\n",
    "            beta = self.softmax(beta)\n",
    "            gamma = beta.detach().clone()\n",
    "\n",
    "            for _ in range(16):\n",
    "                beta = self.attention_linear_1d_1(alpha)\n",
    "                gamma = torch.cat((gamma, beta), dim=1)\n",
    "            gamma = self.softmax(gamma)\n",
    "\n",
    "            for _ in range(17):\n",
    "                t = t + gamma[:, _, :]\n",
    "\n",
    "            t = self.relu(t)\n",
    "            return t\n",
    "\n",
    "        elif self.shape == 1:\n",
    "            t = inputs\n",
    "            t = self.conv2d_1(t)\n",
    "            t = self.batch_norm_2d_1(t)\n",
    "            t = self.relu(t)\n",
    "            t = self.dropout_(t)\n",
    "\n",
    "            t = self.conv2d_2(t)\n",
    "            t = self.batch_norm_2d_2(t)\n",
    "            t = self.relu(t)\n",
    "            t = self.dropout_(t)\n",
    "\n",
    "            t = self.conv2d_3(t)\n",
    "            t = self.batch_norm_2d_3(t)\n",
    "            t = self.relu(t)\n",
    "\n",
    "            t = self.flatten(t)\n",
    "\n",
    "            return t\n",
    "\n",
    "\n",
    "class CnnBiLSTM1D(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super(CnnBiLSTM1D, self).__init__()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout_ = nn.Dropout(dropout)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # InitConv BLocks\n",
    "        self.block_1 = InitConv(3600, 0.005, 0)\n",
    "        self.block_2 = InitConv(3600, 0.005, 0)\n",
    "\n",
    "        # Bi-Linear\n",
    "        self.bilinear = nn.Bilinear(256, 256, 256)\n",
    "\n",
    "        # Linear Layer\n",
    "        self.linear_1 = nn.Linear(1024, 512, bias=True)\n",
    "        self.linear_2 = nn.Linear(512, 256, bias=True)\n",
    "        self.linear_3 = nn.Linear(256, 128, bias=True)\n",
    "        self.linear_4 = nn.Linear(128, 64, bias=True)\n",
    "        self.out = nn.Linear(64, 17, bias=True)\n",
    "\n",
    "        # Conv Layer\n",
    "        self.conv_1d_1 = nn.Conv1d(1, 8, kernel_size=4, stride=2, bias=True)\n",
    "\n",
    "        # Batch Norm 1D\n",
    "        self.batch_norm_1d_1 = nn.BatchNorm1d(8, eps=0.00001, momentum=0.1)\n",
    "\n",
    "        # Bi-LSTM\n",
    "        self.bi_lstm_1 = nn.LSTM(256, 512, num_layers=2, bias=True, dropout=0.005, bidirectional=True)\n",
    "        self.bi_lstm_2 = nn.LSTM(1024, 1024, num_layers=2, bias=True, dropout=0.002, bidirectional=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        a = inputs.detach().clone()\n",
    "        b = inputs.detach().clone()\n",
    "        b = torch.flip(b, dims=[2])\n",
    "        a = self.block_1(a)\n",
    "        b = self.block_2(b)\n",
    "\n",
    "        t = self.bilinear(a, b)\n",
    "\n",
    "        t = t.view(t.shape[0], 1, t.shape[1])\n",
    "\n",
    "        t, _ = self.bi_lstm_1(t)\n",
    "        t = self.tanh(t)\n",
    "\n",
    "#         t, _ = self.bi_lstm_2(t)\n",
    "#         t = self.tanh(t)\n",
    "\n",
    "        t = t.view(-1, t.shape[2])\n",
    "\n",
    "        t = self.linear_1(t)\n",
    "        t = self.relu(t)\n",
    "\n",
    "        t = self.linear_2(t)\n",
    "        t = self.relu(t)\n",
    "\n",
    "        t = self.linear_3(t)\n",
    "        t = self.relu(t)\n",
    "\n",
    "        t = self.linear_4(t)\n",
    "        t = self.relu(t)\n",
    "\n",
    "        t = self.out(t)\n",
    "\n",
    "        return t\n",
    "\n",
    "\n",
    "\n",
    "network = CnnBiLSTM1D(0.005).to(device)\n",
    "\n",
    "train_loader,test_loader, valid_loader= data_loader(r\"../input/siemenshealthineersheatbeat-classfication/MLII\")\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(test_loader))\n",
    "print(len(valid_loader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  ;Total Train correct: 241  ;Train loss: 164.04254484176636\n",
      "Total Validation correct: 106  ;Validation Loss: 41.789501905441284\n",
      "Validation loss decreased (inf --> 41.789502).  Saving model ...\n",
      "Test Accuracy of the model : 13.77049180327869 %\n",
      "\n",
      "\n",
      "Epoch 1  ;Total Train correct: 585  ;Train loss: 140.6969349384308\n",
      "Total Validation correct: 157  ;Validation Loss: 32.25938153266907\n",
      "Validation loss decreased (41.789502 --> 32.259382).  Saving model ...\n",
      "Test Accuracy of the model : 20.655737704918035 %\n",
      "\n",
      "\n",
      "Epoch 2  ;Total Train correct: 930  ;Train loss: 110.72570645809174\n",
      "Total Validation correct: 356  ;Validation Loss: 25.167691588401794\n",
      "Validation loss decreased (32.259382 --> 25.167692).  Saving model ...\n",
      "Test Accuracy of the model : 38.5792349726776 %\n",
      "\n",
      "\n",
      "Epoch 3  ;Total Train correct: 1428  ;Train loss: 90.81335020065308\n",
      "Total Validation correct: 391  ;Validation Loss: 22.073504209518433\n",
      "Validation loss decreased (25.167692 --> 22.073504).  Saving model ...\n",
      "Test Accuracy of the model : 45.02732240437158 %\n",
      "\n",
      "\n",
      "Epoch 4  ;Total Train correct: 1611  ;Train loss: 80.97408020496368\n",
      "Total Validation correct: 394  ;Validation Loss: 20.0186847448349\n",
      "Validation loss decreased (22.073504 --> 20.018685).  Saving model ...\n",
      "Test Accuracy of the model : 49.8360655737705 %\n",
      "\n",
      "\n",
      "Epoch 5  ;Total Train correct: 1711  ;Train loss: 73.17802691459656\n",
      "Total Validation correct: 468  ;Validation Loss: 17.659823536872864\n",
      "Validation loss decreased (20.018685 --> 17.659824).  Saving model ...\n",
      "Test Accuracy of the model : 51.36612021857923 %\n",
      "\n",
      "\n",
      "Epoch 6  ;Total Train correct: 1966  ;Train loss: 66.83314996957779\n",
      "Total Validation correct: 518  ;Validation Loss: 15.646868169307709\n",
      "Validation loss decreased (17.659824 --> 15.646868).  Saving model ...\n",
      "Test Accuracy of the model : 65.13661202185791 %\n",
      "\n",
      "\n",
      "Epoch 7  ;Total Train correct: 2249  ;Train loss: 59.04917365312576\n",
      "Total Validation correct: 601  ;Validation Loss: 13.968286991119385\n",
      "Validation loss decreased (15.646868 --> 13.968287).  Saving model ...\n",
      "Test Accuracy of the model : 64.48087431693989 %\n",
      "\n",
      "\n",
      "Epoch 8  ;Total Train correct: 2359  ;Train loss: 54.723012149333954\n",
      "Total Validation correct: 600  ;Validation Loss: 13.133619964122772\n",
      "Validation loss decreased (13.968287 --> 13.133620).  Saving model ...\n",
      "Test Accuracy of the model : 67.43169398907104 %\n",
      "\n",
      "\n",
      "Epoch 9  ;Total Train correct: 2502  ;Train loss: 48.90794503688812\n",
      "Total Validation correct: 645  ;Validation Loss: 11.957213282585144\n",
      "Validation loss decreased (13.133620 --> 11.957213).  Saving model ...\n",
      "Test Accuracy of the model : 71.80327868852459 %\n",
      "\n",
      "\n",
      "Epoch 10  ;Total Train correct: 2683  ;Train loss: 44.51284444332123\n",
      "Total Validation correct: 675  ;Validation Loss: 10.831232070922852\n",
      "Validation loss decreased (11.957213 --> 10.831232).  Saving model ...\n",
      "Test Accuracy of the model : 75.19125683060109 %\n",
      "\n",
      "\n",
      "Epoch 11  ;Total Train correct: 2696  ;Train loss: 42.22793060541153\n",
      "Total Validation correct: 697  ;Validation Loss: 9.513923048973083\n",
      "Validation loss decreased (10.831232 --> 9.513923).  Saving model ...\n",
      "Test Accuracy of the model : 77.26775956284153 %\n",
      "\n",
      "\n",
      "Epoch 12  ;Total Train correct: 2773  ;Train loss: 37.53749415278435\n",
      "Total Validation correct: 668  ;Validation Loss: 10.284440219402313\n",
      "Test Accuracy of the model : 74.97267759562841 %\n",
      "\n",
      "\n",
      "Epoch 13  ;Total Train correct: 2740  ;Train loss: 38.90031808614731\n",
      "Total Validation correct: 712  ;Validation Loss: 9.554013907909393\n",
      "Test Accuracy of the model : 82.73224043715847 %\n",
      "\n",
      "\n",
      "Epoch 14  ;Total Train correct: 2865  ;Train loss: 37.31002640724182\n",
      "Total Validation correct: 750  ;Validation Loss: 8.192388117313385\n",
      "Validation loss decreased (9.513923 --> 8.192388).  Saving model ...\n",
      "Test Accuracy of the model : 81.85792349726776 %\n",
      "\n",
      "\n",
      "Epoch 15  ;Total Train correct: 3000  ;Train loss: 32.49406489729881\n",
      "Total Validation correct: 774  ;Validation Loss: 7.328309327363968\n",
      "Validation loss decreased (8.192388 --> 7.328309).  Saving model ...\n",
      "Test Accuracy of the model : 82.40437158469945 %\n",
      "\n",
      "\n",
      "Epoch 16  ;Total Train correct: 3060  ;Train loss: 29.87897127866745\n",
      "Total Validation correct: 792  ;Validation Loss: 7.101992189884186\n",
      "Validation loss decreased (7.328309 --> 7.101992).  Saving model ...\n",
      "Test Accuracy of the model : 84.37158469945355 %\n",
      "\n",
      "\n",
      "Epoch 17  ;Total Train correct: 3204  ;Train loss: 26.46508391201496\n",
      "Total Validation correct: 758  ;Validation Loss: 8.115734845399857\n",
      "Test Accuracy of the model : 87.43169398907104 %\n",
      "\n",
      "\n",
      "Epoch 18  ;Total Train correct: 3127  ;Train loss: 29.580805599689484\n",
      "Total Validation correct: 823  ;Validation Loss: 6.036942929029465\n",
      "Validation loss decreased (7.101992 --> 6.036943).  Saving model ...\n",
      "Test Accuracy of the model : 88.19672131147541 %\n",
      "\n",
      "\n",
      "Epoch 19  ;Total Train correct: 3202  ;Train loss: 25.523483738303185\n",
      "Total Validation correct: 802  ;Validation Loss: 6.7876870930194855\n",
      "Test Accuracy of the model : 89.39890710382514 %\n",
      "\n",
      "\n",
      "Epoch 20  ;Total Train correct: 3313  ;Train loss: 21.19010230898857\n",
      "Total Validation correct: 830  ;Validation Loss: 5.023704171180725\n",
      "Validation loss decreased (6.036943 --> 5.023704).  Saving model ...\n",
      "Test Accuracy of the model : 91.5846994535519 %\n",
      "\n",
      "\n",
      "Epoch 21  ;Total Train correct: 3352  ;Train loss: 20.220828846096992\n",
      "Total Validation correct: 820  ;Validation Loss: 5.137088015675545\n",
      "Test Accuracy of the model : 93.00546448087431 %\n",
      "\n",
      "\n",
      "Epoch 22  ;Total Train correct: 3316  ;Train loss: 22.440883338451385\n",
      "Total Validation correct: 836  ;Validation Loss: 5.168271824717522\n",
      "Test Accuracy of the model : 91.80327868852459 %\n",
      "\n",
      "\n",
      "Epoch 23  ;Total Train correct: 3405  ;Train loss: 16.601874455809593\n",
      "Total Validation correct: 856  ;Validation Loss: 4.513692818582058\n",
      "Validation loss decreased (5.023704 --> 4.513693).  Saving model ...\n",
      "Test Accuracy of the model : 90.92896174863388 %\n",
      "\n",
      "\n",
      "Epoch 24  ;Total Train correct: 3353  ;Train loss: 18.08398872613907\n",
      "Total Validation correct: 861  ;Validation Loss: 4.236255809664726\n",
      "Validation loss decreased (4.513693 --> 4.236256).  Saving model ...\n",
      "Test Accuracy of the model : 94.97267759562843 %\n",
      "\n",
      "\n",
      "Epoch 25  ;Total Train correct: 3430  ;Train loss: 14.476706616580486\n",
      "Total Validation correct: 873  ;Validation Loss: 4.019215419888496\n",
      "Validation loss decreased (4.236256 --> 4.019215).  Saving model ...\n",
      "Test Accuracy of the model : 92.6775956284153 %\n",
      "\n",
      "\n",
      "Epoch 26  ;Total Train correct: 3428  ;Train loss: 14.856965877115726\n",
      "Total Validation correct: 855  ;Validation Loss: 4.552281677722931\n",
      "Test Accuracy of the model : 86.22950819672131 %\n",
      "\n",
      "\n",
      "Epoch 27  ;Total Train correct: 3430  ;Train loss: 14.981212563812733\n",
      "Total Validation correct: 868  ;Validation Loss: 4.235400304198265\n",
      "Test Accuracy of the model : 94.75409836065573 %\n",
      "\n",
      "\n",
      "Epoch 28  ;Total Train correct: 3473  ;Train loss: 13.027255333960056\n",
      "Total Validation correct: 881  ;Validation Loss: 3.278592638671398\n",
      "Validation loss decreased (4.019215 --> 3.278593).  Saving model ...\n",
      "Test Accuracy of the model : 96.39344262295081 %\n",
      "\n",
      "\n",
      "Epoch 29  ;Total Train correct: 3515  ;Train loss: 10.770453549921513\n",
      "Total Validation correct: 882  ;Validation Loss: 3.0794609040021896\n",
      "Validation loss decreased (3.278593 --> 3.079461).  Saving model ...\n",
      "Test Accuracy of the model : 95.95628415300547 %\n",
      "\n",
      "\n",
      "Epoch 30  ;Total Train correct: 3498  ;Train loss: 11.458391815423965\n",
      "Total Validation correct: 804  ;Validation Loss: 6.219097748398781\n",
      "Test Accuracy of the model : 92.1311475409836 %\n",
      "\n",
      "\n",
      "Epoch 31  ;Total Train correct: 3522  ;Train loss: 11.190523818135262\n",
      "Total Validation correct: 869  ;Validation Loss: 3.564923472702503\n",
      "Test Accuracy of the model : 94.97267759562843 %\n",
      "\n",
      "\n",
      "Epoch 32  ;Total Train correct: 3531  ;Train loss: 10.122454438358545\n",
      "Total Validation correct: 860  ;Validation Loss: 3.9540236815810204\n",
      "Test Accuracy of the model : 88.41530054644808 %\n",
      "\n",
      "\n",
      "Epoch 33  ;Total Train correct: 3485  ;Train loss: 12.356274474412203\n",
      "Total Validation correct: 892  ;Validation Loss: 2.274884879589081\n",
      "Validation loss decreased (3.079461 --> 2.274885).  Saving model ...\n",
      "Test Accuracy of the model : 97.04918032786885 %\n",
      "\n",
      "\n",
      "Epoch 34  ;Total Train correct: 3564  ;Train loss: 9.893430020660162\n",
      "Total Validation correct: 874  ;Validation Loss: 2.942080870270729\n",
      "Test Accuracy of the model : 91.80327868852459 %\n",
      "\n",
      "\n",
      "Epoch 35  ;Total Train correct: 3511  ;Train loss: 11.598206330090761\n",
      "Total Validation correct: 872  ;Validation Loss: 2.7979582846164703\n",
      "Test Accuracy of the model : 96.93989071038251 %\n",
      "\n",
      "\n",
      "Epoch 36  ;Total Train correct: 3570  ;Train loss: 8.857455875724554\n",
      "Total Validation correct: 891  ;Validation Loss: 2.2346248254179955\n",
      "Validation loss decreased (2.274885 --> 2.234625).  Saving model ...\n",
      "Test Accuracy of the model : 95.73770491803279 %\n",
      "\n",
      "\n",
      "Epoch 37  ;Total Train correct: 3575  ;Train loss: 8.274218786507845\n",
      "Total Validation correct: 888  ;Validation Loss: 2.521839812397957\n",
      "Test Accuracy of the model : 98.0327868852459 %\n",
      "\n",
      "\n",
      "Epoch 38  ;Total Train correct: 3567  ;Train loss: 9.303423937410116\n",
      "Total Validation correct: 895  ;Validation Loss: 2.1247440055012703\n",
      "Validation loss decreased (2.234625 --> 2.124744).  Saving model ...\n",
      "Test Accuracy of the model : 98.36065573770492 %\n",
      "\n",
      "\n",
      "Epoch 39  ;Total Train correct: 3552  ;Train loss: 8.051453053951263\n",
      "Total Validation correct: 890  ;Validation Loss: 2.244533445686102\n",
      "Test Accuracy of the model : 97.48633879781421 %\n",
      "\n",
      "\n",
      "Epoch 40  ;Total Train correct: 3542  ;Train loss: 9.073351062834263\n",
      "Total Validation correct: 888  ;Validation Loss: 2.2829834818840027\n",
      "Test Accuracy of the model : 97.59562841530055 %\n",
      "\n",
      "\n",
      "Epoch 41  ;Total Train correct: 3574  ;Train loss: 7.721400583162904\n",
      "Total Validation correct: 890  ;Validation Loss: 2.361495293676853\n",
      "Test Accuracy of the model : 97.59562841530055 %\n",
      "\n",
      "\n",
      "Epoch 42  ;Total Train correct: 3571  ;Train loss: 8.006992988288403\n",
      "Total Validation correct: 887  ;Validation Loss: 4.804630316793919\n",
      "Test Accuracy of the model : 97.59562841530055 %\n",
      "\n",
      "\n",
      "Epoch 43  ;Total Train correct: 3571  ;Train loss: 7.991235081106424\n",
      "Total Validation correct: 894  ;Validation Loss: 3.6566744819283485\n",
      "Test Accuracy of the model : 98.0327868852459 %\n",
      "\n",
      "\n",
      "Epoch 44  ;Total Train correct: 3561  ;Train loss: 8.238582758232951\n",
      "Total Validation correct: 897  ;Validation Loss: 1.8535717986524105\n",
      "Validation loss decreased (2.124744 --> 1.853572).  Saving model ...\n",
      "Test Accuracy of the model : 97.81420765027322 %\n",
      "\n",
      "\n",
      "Epoch 45  ;Total Train correct: 3567  ;Train loss: 8.028588686138391\n",
      "Total Validation correct: 898  ;Validation Loss: 2.003752624616027\n",
      "Test Accuracy of the model : 97.59562841530055 %\n",
      "\n",
      "\n",
      "Epoch 46  ;Total Train correct: 3423  ;Train loss: 14.18351436778903\n",
      "Total Validation correct: 805  ;Validation Loss: 5.502663388848305\n",
      "Test Accuracy of the model : 91.91256830601094 %\n",
      "\n",
      "\n",
      "Epoch 47  ;Total Train correct: 3426  ;Train loss: 16.097184117883444\n",
      "Total Validation correct: 876  ;Validation Loss: 2.9436572417616844\n",
      "Test Accuracy of the model : 92.34972677595628 %\n",
      "\n",
      "\n",
      "Epoch 48  ;Total Train correct: 3528  ;Train loss: 10.146668151021004\n",
      "Total Validation correct: 868  ;Validation Loss: 2.477318551391363\n",
      "Test Accuracy of the model : 95.51912568306011 %\n",
      "\n",
      "\n",
      "Epoch 49  ;Total Train correct: 3530  ;Train loss: 9.365026023238897\n",
      "Total Validation correct: 897  ;Validation Loss: 1.7071613874286413\n",
      "Validation loss decreased (1.853572 --> 1.707161).  Saving model ...\n",
      "Test Accuracy of the model : 95.62841530054644 %\n",
      "\n",
      "\n",
      "Epoch 50  ;Total Train correct: 3560  ;Train loss: 7.491213086992502\n",
      "Total Validation correct: 896  ;Validation Loss: 1.486779410392046\n",
      "Validation loss decreased (1.707161 --> 1.486779).  Saving model ...\n",
      "Test Accuracy of the model : 97.81420765027322 %\n",
      "\n",
      "\n",
      "Epoch 51  ;Total Train correct: 3555  ;Train loss: 8.354517679661512\n",
      "Total Validation correct: 872  ;Validation Loss: 2.530447207391262\n",
      "Test Accuracy of the model : 95.51912568306011 %\n",
      "\n",
      "\n",
      "Epoch 52  ;Total Train correct: 3550  ;Train loss: 8.06367739662528\n",
      "Total Validation correct: 874  ;Validation Loss: 3.4917820803821087\n",
      "Test Accuracy of the model : 91.69398907103825 %\n",
      "\n",
      "\n",
      "Epoch 53  ;Total Train correct: 3430  ;Train loss: 13.538333415053785\n",
      "Total Validation correct: 884  ;Validation Loss: 2.7028093710541725\n",
      "Test Accuracy of the model : 97.70491803278688 %\n",
      "\n",
      "\n",
      "Epoch 54  ;Total Train correct: 3557  ;Train loss: 7.176397994160652\n",
      "Total Validation correct: 889  ;Validation Loss: 1.7425474394112825\n",
      "Test Accuracy of the model : 97.70491803278688 %\n",
      "\n",
      "\n",
      "Epoch 55  ;Total Train correct: 3571  ;Train loss: 7.992823224514723\n",
      "Total Validation correct: 887  ;Validation Loss: 2.0591833759099245\n",
      "Test Accuracy of the model : 98.0327868852459 %\n",
      "\n",
      "\n",
      "Epoch 56  ;Total Train correct: 3570  ;Train loss: 7.623734299093485\n",
      "Total Validation correct: 856  ;Validation Loss: 3.9293541833758354\n",
      "Test Accuracy of the model : 86.88524590163934 %\n",
      "\n",
      "\n",
      "Epoch 57  ;Total Train correct: 3420  ;Train loss: 15.635734844952822\n",
      "Total Validation correct: 867  ;Validation Loss: 2.91421590000391\n",
      "Test Accuracy of the model : 96.93989071038251 %\n",
      "\n",
      "\n",
      "Epoch 58  ;Total Train correct: 3555  ;Train loss: 7.866173340007663\n",
      "Total Validation correct: 878  ;Validation Loss: 2.0943305864930153\n",
      "Test Accuracy of the model : 96.28415300546447 %\n",
      "\n",
      "\n",
      "Epoch 59  ;Total Train correct: 3501  ;Train loss: 9.870082650333643\n",
      "Total Validation correct: 881  ;Validation Loss: 2.114694744348526\n",
      "Test Accuracy of the model : 96.83060109289617 %\n",
      "\n",
      "\n",
      "Epoch 60  ;Total Train correct: 3539  ;Train loss: 8.28747402690351\n",
      "Total Validation correct: 886  ;Validation Loss: 2.6802117191255093\n",
      "Test Accuracy of the model : 96.50273224043715 %\n",
      "\n",
      "\n",
      "Epoch 61  ;Total Train correct: 3515  ;Train loss: 10.532330928370357\n",
      "Total Validation correct: 879  ;Validation Loss: 3.7382153682410717\n",
      "Test Accuracy of the model : 94.31693989071039 %\n",
      "\n",
      "\n",
      "Epoch 62  ;Total Train correct: 3456  ;Train loss: 14.39550368860364\n",
      "Total Validation correct: 877  ;Validation Loss: 2.7298813946545124\n",
      "Test Accuracy of the model : 95.30054644808743 %\n",
      "\n",
      "\n",
      "Epoch 63  ;Total Train correct: 3544  ;Train loss: 9.639809612184763\n",
      "Total Validation correct: 885  ;Validation Loss: 2.366337340325117\n",
      "Test Accuracy of the model : 96.50273224043715 %\n",
      "\n",
      "\n",
      "Epoch 64  ;Total Train correct: 3571  ;Train loss: 8.143286306411028\n",
      "Total Validation correct: 890  ;Validation Loss: 1.9079312644898891\n",
      "Test Accuracy of the model : 98.36065573770492 %\n",
      "\n",
      "\n",
      "Epoch 65  ;Total Train correct: 3588  ;Train loss: 6.41356148198247\n",
      "Total Validation correct: 886  ;Validation Loss: 2.3538586404174566\n",
      "Test Accuracy of the model : 98.14207650273225 %\n",
      "\n",
      "\n",
      "Epoch 66  ;Total Train correct: 3579  ;Train loss: 7.406266251578927\n",
      "Total Validation correct: 888  ;Validation Loss: 2.2433810234069824\n",
      "Test Accuracy of the model : 98.25136612021858 %\n",
      "\n",
      "\n",
      "Epoch 67  ;Total Train correct: 3592  ;Train loss: 6.933481844142079\n",
      "Total Validation correct: 856  ;Validation Loss: 4.129290748387575\n",
      "Test Accuracy of the model : 96.28415300546447 %\n",
      "\n",
      "\n",
      "Epoch 68  ;Total Train correct: 3506  ;Train loss: 10.2215218488127\n",
      "Total Validation correct: 870  ;Validation Loss: 3.461660146713257\n",
      "Test Accuracy of the model : 97.48633879781421 %\n",
      "\n",
      "\n",
      "Epoch 69  ;Total Train correct: 3534  ;Train loss: 14.182043310254812\n",
      "Total Validation correct: 883  ;Validation Loss: 2.5000270679593086\n",
      "Test Accuracy of the model : 96.83060109289617 %\n",
      "\n",
      "\n",
      "Epoch 70  ;Total Train correct: 3551  ;Train loss: 11.858259787783027\n",
      "Total Validation correct: 886  ;Validation Loss: 2.3715355694293976\n",
      "Test Accuracy of the model : 97.26775956284153 %\n",
      "\n",
      "\n",
      "Epoch 71  ;Total Train correct: 3541  ;Train loss: 10.425522055476904\n",
      "Total Validation correct: 886  ;Validation Loss: 2.3082119319587946\n",
      "Test Accuracy of the model : 96.50273224043715 %\n",
      "\n",
      "\n",
      "Epoch 72  ;Total Train correct: 3553  ;Train loss: 9.985654808580875\n",
      "Total Validation correct: 889  ;Validation Loss: 2.133767381310463\n",
      "Test Accuracy of the model : 97.48633879781421 %\n",
      "\n",
      "\n",
      "Epoch 73  ;Total Train correct: 3573  ;Train loss: 9.60858866199851\n",
      "Total Validation correct: 895  ;Validation Loss: 2.408669274300337\n",
      "Test Accuracy of the model : 97.81420765027322 %\n",
      "\n",
      "\n",
      "Epoch 74  ;Total Train correct: 3579  ;Train loss: 9.488870171830058\n",
      "Total Validation correct: 900  ;Validation Loss: 1.8659692145884037\n",
      "Test Accuracy of the model : 97.81420765027322 %\n",
      "\n",
      "\n",
      "Epoch 75  ;Total Train correct: 3577  ;Train loss: 11.813709314912558\n",
      "Total Validation correct: 889  ;Validation Loss: 3.196959886699915\n",
      "Test Accuracy of the model : 97.48633879781421 %\n",
      "\n",
      "\n",
      "Epoch 76  ;Total Train correct: 3572  ;Train loss: 8.776981925591826\n",
      "Total Validation correct: 894  ;Validation Loss: 2.3041234128177166\n",
      "Test Accuracy of the model : 96.50273224043715 %\n",
      "\n",
      "\n",
      "Epoch 77  ;Total Train correct: 3585  ;Train loss: 7.767057361081243\n",
      "Total Validation correct: 886  ;Validation Loss: 2.6639734618365765\n",
      "Test Accuracy of the model : 97.04918032786885 %\n",
      "\n",
      "\n",
      "Epoch 78  ;Total Train correct: 3559  ;Train loss: 8.60060565546155\n",
      "Total Validation correct: 894  ;Validation Loss: 1.8039506897330284\n",
      "Test Accuracy of the model : 97.48633879781421 %\n",
      "\n",
      "\n",
      "Epoch 79  ;Total Train correct: 3584  ;Train loss: 9.180580735206604\n",
      "Total Validation correct: 863  ;Validation Loss: 2.930898979306221\n",
      "Test Accuracy of the model : 92.45901639344262 %\n",
      "\n",
      "\n",
      "Epoch 80  ;Total Train correct: 3360  ;Train loss: 18.290808398276567\n",
      "Total Validation correct: 787  ;Validation Loss: 5.702284500002861\n",
      "Test Accuracy of the model : 84.59016393442623 %\n",
      "\n",
      "\n",
      "Epoch 81  ;Total Train correct: 3230  ;Train loss: 19.16754476726055\n",
      "Total Validation correct: 793  ;Validation Loss: 4.957964226603508\n",
      "Test Accuracy of the model : 86.66666666666667 %\n",
      "\n",
      "\n",
      "Epoch 82  ;Total Train correct: 3221  ;Train loss: 19.56048733741045\n",
      "Total Validation correct: 792  ;Validation Loss: 4.593646138906479\n",
      "Test Accuracy of the model : 85.02732240437159 %\n",
      "\n",
      "\n",
      "Epoch 83  ;Total Train correct: 3247  ;Train loss: 19.57148350775242\n",
      "Total Validation correct: 827  ;Validation Loss: 4.813899576663971\n",
      "Test Accuracy of the model : 88.85245901639345 %\n",
      "\n",
      "\n",
      "Epoch 84  ;Total Train correct: 3396  ;Train loss: 14.721603848040104\n",
      "Total Validation correct: 820  ;Validation Loss: 4.62396439909935\n",
      "Test Accuracy of the model : 91.36612021857924 %\n",
      "\n",
      "\n",
      "Epoch 85  ;Total Train correct: 3415  ;Train loss: 13.738923236727715\n",
      "Total Validation correct: 849  ;Validation Loss: 3.6634988635778427\n",
      "Test Accuracy of the model : 91.69398907103825 %\n",
      "\n",
      "\n",
      "Epoch 86  ;Total Train correct: 3415  ;Train loss: 13.76985478028655\n",
      "Total Validation correct: 850  ;Validation Loss: 4.935781575739384\n",
      "Test Accuracy of the model : 95.19125683060109 %\n",
      "\n",
      "\n",
      "Epoch 87  ;Total Train correct: 3417  ;Train loss: 13.897113487124443\n",
      "Total Validation correct: 844  ;Validation Loss: 4.142578288912773\n",
      "Test Accuracy of the model : 96.28415300546447 %\n",
      "\n",
      "\n",
      "Epoch 88  ;Total Train correct: 3441  ;Train loss: 13.11445065587759\n",
      "Total Validation correct: 862  ;Validation Loss: 3.8456150628626347\n",
      "Test Accuracy of the model : 95.62841530054644 %\n",
      "\n",
      "\n",
      "Epoch 89  ;Total Train correct: 3440  ;Train loss: 13.742245692759752\n",
      "Total Validation correct: 851  ;Validation Loss: 4.619938902556896\n",
      "Test Accuracy of the model : 96.72131147540983 %\n",
      "\n",
      "\n",
      "Epoch 90  ;Total Train correct: 3503  ;Train loss: 12.446043480187654\n",
      "Total Validation correct: 864  ;Validation Loss: 3.71082878485322\n",
      "Test Accuracy of the model : 96.50273224043715 %\n",
      "\n",
      "\n",
      "Epoch 91  ;Total Train correct: 3549  ;Train loss: 10.437731679528952\n",
      "Total Validation correct: 876  ;Validation Loss: 3.366579819470644\n",
      "Test Accuracy of the model : 97.48633879781421 %\n",
      "\n",
      "\n",
      "Epoch 92  ;Total Train correct: 3371  ;Train loss: 16.037977028638124\n",
      "Total Validation correct: 836  ;Validation Loss: 5.294650264084339\n",
      "Test Accuracy of the model : 90.1639344262295 %\n",
      "\n",
      "\n",
      "Epoch 93  ;Total Train correct: 3328  ;Train loss: 14.70195297151804\n",
      "Total Validation correct: 842  ;Validation Loss: 4.119390293955803\n",
      "Test Accuracy of the model : 90.60109289617486 %\n",
      "\n",
      "\n",
      "Epoch 94  ;Total Train correct: 3341  ;Train loss: 13.144437275826931\n",
      "Total Validation correct: 854  ;Validation Loss: 3.9202512577176094\n",
      "Test Accuracy of the model : 91.69398907103825 %\n",
      "\n",
      "\n",
      "Epoch 95  ;Total Train correct: 3328  ;Train loss: 14.520275451242924\n",
      "Total Validation correct: 839  ;Validation Loss: 4.267096310853958\n",
      "Test Accuracy of the model : 91.36612021857924 %\n",
      "\n",
      "\n",
      "Epoch 96  ;Total Train correct: 3353  ;Train loss: 17.094119504094124\n",
      "Total Validation correct: 830  ;Validation Loss: 3.835798218846321\n",
      "Test Accuracy of the model : 91.14754098360656 %\n",
      "\n",
      "\n",
      "Epoch 97  ;Total Train correct: 3326  ;Train loss: 20.94933583587408\n",
      "Total Validation correct: 828  ;Validation Loss: 5.1737194657325745\n",
      "Test Accuracy of the model : 91.5846994535519 %\n",
      "\n",
      "\n",
      "Epoch 98  ;Total Train correct: 3343  ;Train loss: 14.40116272866726\n",
      "Total Validation correct: 815  ;Validation Loss: 4.989466264843941\n",
      "Test Accuracy of the model : 86.12021857923497 %\n",
      "\n",
      "\n",
      "Epoch 99  ;Total Train correct: 3312  ;Train loss: 16.79468359053135\n",
      "Total Validation correct: 830  ;Validation Loss: 3.8935383409261703\n",
      "Test Accuracy of the model : 91.69398907103825 %\n",
      "\n",
      "\n",
      "Epoch 100  ;Total Train correct: 3379  ;Train loss: 14.31282763183117\n",
      "Total Validation correct: 848  ;Validation Loss: 3.837684005498886\n",
      "Test Accuracy of the model : 91.14754098360656 %\n",
      "\n",
      "\n",
      "Epoch 101  ;Total Train correct: 3300  ;Train loss: 16.82080154493451\n",
      "Total Validation correct: 845  ;Validation Loss: 3.6151135563850403\n",
      "Test Accuracy of the model : 89.94535519125682 %\n",
      "\n",
      "\n",
      "Epoch 102  ;Total Train correct: 3336  ;Train loss: 17.19027841091156\n",
      "Total Validation correct: 836  ;Validation Loss: 4.38292983174324\n",
      "Test Accuracy of the model : 90.1639344262295 %\n",
      "\n",
      "\n",
      "Epoch 103  ;Total Train correct: 3311  ;Train loss: 17.298855029046535\n",
      "Total Validation correct: 849  ;Validation Loss: 4.0039963722229\n",
      "Test Accuracy of the model : 91.5846994535519 %\n",
      "\n",
      "\n",
      "Epoch 104  ;Total Train correct: 3291  ;Train loss: 17.425600729882717\n",
      "Total Validation correct: 789  ;Validation Loss: 7.092853710055351\n",
      "Test Accuracy of the model : 84.15300546448088 %\n",
      "\n",
      "\n",
      "Epoch 105  ;Total Train correct: 3186  ;Train loss: 23.080023124814034\n",
      "Total Validation correct: 835  ;Validation Loss: 5.750789061188698\n",
      "Test Accuracy of the model : 85.02732240437159 %\n",
      "\n",
      "\n",
      "Epoch 106  ;Total Train correct: 3238  ;Train loss: 23.609972566366196\n",
      "Total Validation correct: 822  ;Validation Loss: 5.432642474770546\n",
      "Test Accuracy of the model : 87.8688524590164 %\n",
      "\n",
      "\n",
      "Epoch 107  ;Total Train correct: 3254  ;Train loss: 21.043184354901314\n",
      "Total Validation correct: 800  ;Validation Loss: 6.037926658987999\n",
      "Test Accuracy of the model : 86.22950819672131 %\n",
      "\n",
      "\n",
      "Epoch 108  ;Total Train correct: 3261  ;Train loss: 23.036314263939857\n",
      "Total Validation correct: 822  ;Validation Loss: 4.77728620916605\n",
      "Test Accuracy of the model : 90.60109289617486 %\n",
      "\n",
      "\n",
      "Epoch 109  ;Total Train correct: 3393  ;Train loss: 17.72634319216013\n",
      "Total Validation correct: 833  ;Validation Loss: 6.137470036745071\n",
      "Test Accuracy of the model : 96.17486338797814 %\n",
      "\n",
      "\n",
      "Epoch 110  ;Total Train correct: 3417  ;Train loss: 16.956290274858475\n",
      "Total Validation correct: 860  ;Validation Loss: 4.104944691061974\n",
      "Test Accuracy of the model : 95.95628415300547 %\n",
      "\n",
      "\n",
      "Epoch 111  ;Total Train correct: 3428  ;Train loss: 18.53939003869891\n",
      "Total Validation correct: 816  ;Validation Loss: 6.014018774032593\n",
      "Test Accuracy of the model : 91.80327868852459 %\n",
      "\n",
      "\n",
      "Epoch 112  ;Total Train correct: 3433  ;Train loss: 16.560578130185604\n",
      "Total Validation correct: 837  ;Validation Loss: 4.425486505031586\n",
      "Test Accuracy of the model : 96.61202185792351 %\n",
      "\n",
      "\n",
      "Epoch 113  ;Total Train correct: 3458  ;Train loss: 15.931906066834927\n",
      "Total Validation correct: 881  ;Validation Loss: 3.1843626387417316\n",
      "Test Accuracy of the model : 97.04918032786885 %\n",
      "\n",
      "\n",
      "Epoch 114  ;Total Train correct: 3502  ;Train loss: 13.836996749043465\n",
      "Total Validation correct: 870  ;Validation Loss: 3.2443634644150734\n",
      "Test Accuracy of the model : 95.84699453551913 %\n",
      "\n",
      "\n",
      "Epoch 115  ;Total Train correct: 3440  ;Train loss: 15.861999649554491\n",
      "Total Validation correct: 873  ;Validation Loss: 3.384744517505169\n",
      "Test Accuracy of the model : 95.84699453551913 %\n",
      "\n",
      "\n",
      "Epoch 116  ;Total Train correct: 3487  ;Train loss: 12.708220280706882\n",
      "Total Validation correct: 879  ;Validation Loss: 2.757302850484848\n",
      "Test Accuracy of the model : 96.50273224043715 %\n",
      "\n",
      "\n",
      "Epoch 117  ;Total Train correct: 3510  ;Train loss: 12.311627440154552\n",
      "Total Validation correct: 852  ;Validation Loss: 4.518858131021261\n",
      "Test Accuracy of the model : 94.09836065573771 %\n",
      "\n",
      "\n",
      "Epoch 118  ;Total Train correct: 3427  ;Train loss: 14.801619529724121\n",
      "Total Validation correct: 870  ;Validation Loss: 3.553905725479126\n",
      "Test Accuracy of the model : 96.17486338797814 %\n",
      "\n",
      "\n",
      "Epoch 119  ;Total Train correct: 3501  ;Train loss: 12.420833755284548\n",
      "Total Validation correct: 872  ;Validation Loss: 3.7002658769488335\n",
      "Test Accuracy of the model : 95.95628415300547 %\n",
      "\n",
      "\n",
      "Epoch 120  ;Total Train correct: 3497  ;Train loss: 14.098647635430098\n",
      "Total Validation correct: 871  ;Validation Loss: 3.548883803188801\n",
      "Test Accuracy of the model : 96.17486338797814 %\n",
      "\n",
      "\n",
      "Epoch 121  ;Total Train correct: 3516  ;Train loss: 12.576864756643772\n",
      "Total Validation correct: 859  ;Validation Loss: 3.979413203895092\n",
      "Test Accuracy of the model : 93.66120218579235 %\n",
      "\n",
      "\n",
      "Epoch 122  ;Total Train correct: 3516  ;Train loss: 12.39726833999157\n",
      "Total Validation correct: 881  ;Validation Loss: 3.266739096492529\n",
      "Test Accuracy of the model : 96.39344262295081 %\n",
      "\n",
      "\n",
      "Epoch 123  ;Total Train correct: 3517  ;Train loss: 11.68311671167612\n",
      "Total Validation correct: 878  ;Validation Loss: 3.8561009131371975\n",
      "Test Accuracy of the model : 96.39344262295081 %\n",
      "\n",
      "\n",
      "Epoch 124  ;Total Train correct: 3456  ;Train loss: 19.15763211250305\n",
      "Total Validation correct: 878  ;Validation Loss: 4.196825299412012\n",
      "Test Accuracy of the model : 95.62841530054644 %\n",
      "\n",
      "\n",
      "Epoch 125  ;Total Train correct: 3494  ;Train loss: 16.329831451177597\n",
      "Total Validation correct: 867  ;Validation Loss: 6.0089606791734695\n",
      "Test Accuracy of the model : 95.73770491803279 %\n",
      "\n",
      "\n",
      "Epoch 126  ;Total Train correct: 3457  ;Train loss: 23.717921152710915\n",
      "Total Validation correct: 859  ;Validation Loss: 4.866406425833702\n",
      "Test Accuracy of the model : 93.98907103825137 %\n",
      "\n",
      "\n",
      "Epoch 127  ;Total Train correct: 3468  ;Train loss: 19.385260485112667\n",
      "Total Validation correct: 863  ;Validation Loss: 4.785538837313652\n",
      "Test Accuracy of the model : 94.86338797814207 %\n",
      "\n",
      "\n",
      "Epoch 128  ;Total Train correct: 3524  ;Train loss: 14.318917229771614\n",
      "Total Validation correct: 875  ;Validation Loss: 4.667548105120659\n",
      "Test Accuracy of the model : 95.40983606557377 %\n",
      "\n",
      "\n",
      "Epoch 129  ;Total Train correct: 3525  ;Train loss: 14.190802607685328\n",
      "Total Validation correct: 877  ;Validation Loss: 4.651278004050255\n",
      "Test Accuracy of the model : 95.08196721311475 %\n",
      "\n",
      "\n",
      "Epoch 130  ;Total Train correct: 3506  ;Train loss: 13.374327182769775\n",
      "Total Validation correct: 875  ;Validation Loss: 4.198313556611538\n",
      "Test Accuracy of the model : 96.39344262295081 %\n",
      "\n",
      "\n",
      "Epoch 131  ;Total Train correct: 3499  ;Train loss: 13.854903500527143\n",
      "Total Validation correct: 870  ;Validation Loss: 4.744140565395355\n",
      "Test Accuracy of the model : 90.92896174863388 %\n",
      "\n",
      "\n",
      "Epoch 132  ;Total Train correct: 3426  ;Train loss: 22.213419400155544\n",
      "Total Validation correct: 840  ;Validation Loss: 6.7758194878697395\n",
      "Test Accuracy of the model : 94.64480874316939 %\n",
      "\n",
      "\n",
      "Epoch 133  ;Total Train correct: 3505  ;Train loss: 14.19401629269123\n",
      "Total Validation correct: 867  ;Validation Loss: 4.385329321026802\n",
      "Test Accuracy of the model : 95.08196721311475 %\n",
      "\n",
      "\n",
      "Epoch 134  ;Total Train correct: 3484  ;Train loss: 15.293595753610134\n",
      "Total Validation correct: 863  ;Validation Loss: 5.16385904699564\n",
      "Test Accuracy of the model : 92.6775956284153 %\n",
      "\n",
      "\n",
      "Epoch 135  ;Total Train correct: 3324  ;Train loss: 19.474769711494446\n",
      "Total Validation correct: 826  ;Validation Loss: 7.427822560071945\n",
      "Test Accuracy of the model : 90.3825136612022 %\n",
      "\n",
      "\n",
      "Epoch 136  ;Total Train correct: 3358  ;Train loss: 33.53236509859562\n",
      "Total Validation correct: 856  ;Validation Loss: 5.717843994498253\n",
      "Test Accuracy of the model : 95.51912568306011 %\n",
      "\n",
      "\n",
      "Epoch 137  ;Total Train correct: 3453  ;Train loss: 24.392265044152737\n",
      "Total Validation correct: 811  ;Validation Loss: 13.467521280050278\n",
      "Test Accuracy of the model : 90.92896174863388 %\n",
      "\n",
      "\n",
      "Epoch 138  ;Total Train correct: 3164  ;Train loss: 37.49065285921097\n",
      "Total Validation correct: 811  ;Validation Loss: 7.277191489934921\n",
      "Test Accuracy of the model : 91.5846994535519 %\n",
      "\n",
      "\n",
      "Epoch 139  ;Total Train correct: 3388  ;Train loss: 23.431481063365936\n",
      "Total Validation correct: 881  ;Validation Loss: 4.902227200567722\n",
      "Test Accuracy of the model : 95.19125683060109 %\n",
      "\n",
      "\n",
      "Epoch 140  ;Total Train correct: 3493  ;Train loss: 18.80637399852276\n",
      "Total Validation correct: 857  ;Validation Loss: 5.521907150745392\n",
      "Test Accuracy of the model : 92.24043715846994 %\n",
      "\n",
      "\n",
      "Epoch 141  ;Total Train correct: 3441  ;Train loss: 21.23775465786457\n",
      "Total Validation correct: 827  ;Validation Loss: 7.31300388276577\n",
      "Test Accuracy of the model : 84.37158469945355 %\n",
      "\n",
      "\n",
      "Epoch 142  ;Total Train correct: 3339  ;Train loss: 28.10972337424755\n",
      "Total Validation correct: 854  ;Validation Loss: 6.2748110592365265\n",
      "Test Accuracy of the model : 93.22404371584699 %\n",
      "\n",
      "\n",
      "Epoch 143  ;Total Train correct: 3324  ;Train loss: 28.756277292966843\n",
      "Total Validation correct: 848  ;Validation Loss: 5.703583061695099\n",
      "Test Accuracy of the model : 92.78688524590164 %\n",
      "\n",
      "\n",
      "Epoch 144  ;Total Train correct: 3403  ;Train loss: 21.112288124859333\n",
      "Total Validation correct: 858  ;Validation Loss: 5.341843008995056\n",
      "Test Accuracy of the model : 93.22404371584699 %\n",
      "\n",
      "\n",
      "Epoch 145  ;Total Train correct: 3412  ;Train loss: 21.48554166406393\n",
      "Total Validation correct: 865  ;Validation Loss: 4.893523350358009\n",
      "Test Accuracy of the model : 93.77049180327869 %\n",
      "\n",
      "\n",
      "Epoch 146  ;Total Train correct: 3406  ;Train loss: 20.746718749403954\n",
      "Total Validation correct: 828  ;Validation Loss: 6.05360321700573\n",
      "Test Accuracy of the model : 90.05464480874316 %\n",
      "\n",
      "\n",
      "Epoch 147  ;Total Train correct: 3217  ;Train loss: 26.338412955403328\n",
      "Total Validation correct: 820  ;Validation Loss: 6.309507310390472\n",
      "Test Accuracy of the model : 87.75956284153006 %\n",
      "\n",
      "\n",
      "Epoch 148  ;Total Train correct: 3257  ;Train loss: 23.212233752012253\n",
      "Total Validation correct: 828  ;Validation Loss: 6.0460288524627686\n",
      "Test Accuracy of the model : 86.88524590163934 %\n",
      "\n",
      "\n",
      "Epoch 149  ;Total Train correct: 3203  ;Train loss: 22.973748102784157\n",
      "Total Validation correct: 814  ;Validation Loss: 6.109953224658966\n",
      "Test Accuracy of the model : 88.41530054644808 %\n",
      "\n",
      "\n",
      "Epoch 150  ;Total Train correct: 3221  ;Train loss: 23.793588414788246\n",
      "Total Validation correct: 767  ;Validation Loss: 7.852153405547142\n",
      "Test Accuracy of the model : 88.74316939890711 %\n",
      "\n",
      "\n",
      "Epoch 151  ;Total Train correct: 3150  ;Train loss: 25.77180863916874\n",
      "Total Validation correct: 779  ;Validation Loss: 7.525237053632736\n",
      "Test Accuracy of the model : 85.24590163934425 %\n",
      "\n",
      "\n",
      "Epoch 152  ;Total Train correct: 3201  ;Train loss: 24.108599305152893\n",
      "Total Validation correct: 804  ;Validation Loss: 6.848934561014175\n",
      "Test Accuracy of the model : 87.97814207650273 %\n",
      "\n",
      "\n",
      "Epoch 153  ;Total Train correct: 3293  ;Train loss: 22.36133137345314\n",
      "Total Validation correct: 829  ;Validation Loss: 6.448512852191925\n",
      "Test Accuracy of the model : 92.89617486338798 %\n",
      "\n",
      "\n",
      "Epoch 154  ;Total Train correct: 3391  ;Train loss: 18.536533564329147\n",
      "Total Validation correct: 852  ;Validation Loss: 4.796106301248074\n",
      "Test Accuracy of the model : 93.55191256830601 %\n",
      "\n",
      "\n",
      "Epoch 155  ;Total Train correct: 3341  ;Train loss: 27.9417375177145\n",
      "Total Validation correct: 828  ;Validation Loss: 8.811516284942627\n",
      "Test Accuracy of the model : 93.87978142076503 %\n",
      "\n",
      "\n",
      "Epoch 156  ;Total Train correct: 3374  ;Train loss: 19.967314571142197\n",
      "Total Validation correct: 799  ;Validation Loss: 8.401276901364326\n",
      "Test Accuracy of the model : 84.48087431693989 %\n",
      "\n",
      "\n",
      "Epoch 157  ;Total Train correct: 3317  ;Train loss: 19.527574852108955\n",
      "Total Validation correct: 825  ;Validation Loss: 5.008762389421463\n",
      "Test Accuracy of the model : 93.55191256830601 %\n",
      "\n",
      "\n",
      "Epoch 158  ;Total Train correct: 3407  ;Train loss: 15.821596577763557\n",
      "Total Validation correct: 855  ;Validation Loss: 4.8068170845508575\n",
      "Test Accuracy of the model : 93.98907103825137 %\n",
      "\n",
      "\n",
      "Epoch 159  ;Total Train correct: 3368  ;Train loss: 22.18023891746998\n",
      "Total Validation correct: 822  ;Validation Loss: 8.398506984114647\n",
      "Test Accuracy of the model : 91.5846994535519 %\n",
      "\n",
      "\n",
      "Epoch 160  ;Total Train correct: 3404  ;Train loss: 22.725090600550175\n",
      "Total Validation correct: 844  ;Validation Loss: 5.450899600982666\n",
      "Test Accuracy of the model : 93.22404371584699 %\n",
      "\n",
      "\n",
      "Epoch 161  ;Total Train correct: 3420  ;Train loss: 15.947964236140251\n",
      "Total Validation correct: 842  ;Validation Loss: 4.92943400144577\n",
      "Test Accuracy of the model : 89.72677595628416 %\n",
      "\n",
      "\n",
      "Epoch 162  ;Total Train correct: 3440  ;Train loss: 15.516936104744673\n",
      "Total Validation correct: 869  ;Validation Loss: 4.293038934469223\n",
      "Test Accuracy of the model : 95.30054644808743 %\n",
      "\n",
      "\n",
      "Epoch 163  ;Total Train correct: 3486  ;Train loss: 13.947935488075018\n",
      "Total Validation correct: 869  ;Validation Loss: 4.026879422366619\n",
      "Test Accuracy of the model : 95.62841530054644 %\n",
      "\n",
      "\n",
      "Epoch 164  ;Total Train correct: 3501  ;Train loss: 12.91084885597229\n",
      "Total Validation correct: 872  ;Validation Loss: 3.6940370202064514\n",
      "Test Accuracy of the model : 95.51912568306011 %\n",
      "\n",
      "\n",
      "Epoch 165  ;Total Train correct: 3502  ;Train loss: 12.796974319964647\n",
      "Total Validation correct: 870  ;Validation Loss: 3.343585016205907\n",
      "Test Accuracy of the model : 93.33333333333333 %\n",
      "\n",
      "\n",
      "Epoch 166  ;Total Train correct: 3491  ;Train loss: 12.552503757178783\n",
      "Total Validation correct: 867  ;Validation Loss: 3.5491517409682274\n",
      "Test Accuracy of the model : 94.75409836065573 %\n",
      "\n",
      "\n",
      "Epoch 167  ;Total Train correct: 3402  ;Train loss: 23.905695267021656\n",
      "Total Validation correct: 831  ;Validation Loss: 6.7328134924173355\n",
      "Test Accuracy of the model : 92.6775956284153 %\n",
      "\n",
      "\n",
      "Epoch 168  ;Total Train correct: 3374  ;Train loss: 36.898733392357826\n",
      "Total Validation correct: 838  ;Validation Loss: 6.651303380727768\n",
      "Test Accuracy of the model : 91.69398907103825 %\n",
      "\n",
      "\n",
      "Epoch 169  ;Total Train correct: 3135  ;Train loss: 30.90031662583351\n",
      "Total Validation correct: 707  ;Validation Loss: 12.485177874565125\n",
      "Test Accuracy of the model : 66.55737704918033 %\n",
      "\n",
      "\n",
      "Epoch 170  ;Total Train correct: 2645  ;Train loss: 50.86926829814911\n",
      "Total Validation correct: 697  ;Validation Loss: 10.620285630226135\n",
      "Test Accuracy of the model : 68.7431693989071 %\n",
      "\n",
      "\n",
      "Epoch 171  ;Total Train correct: 2809  ;Train loss: 38.867040902376175\n",
      "Total Validation correct: 712  ;Validation Loss: 9.740955084562302\n",
      "Test Accuracy of the model : 79.45355191256832 %\n",
      "\n",
      "\n",
      "Epoch 172  ;Total Train correct: 3019  ;Train loss: 32.51027995347977\n",
      "Total Validation correct: 759  ;Validation Loss: 8.565855026245117\n",
      "Test Accuracy of the model : 83.49726775956285 %\n",
      "\n",
      "\n",
      "Epoch 173  ;Total Train correct: 3162  ;Train loss: 30.895953193306923\n",
      "Total Validation correct: 766  ;Validation Loss: 9.008130520582199\n",
      "Test Accuracy of the model : 83.16939890710383 %\n",
      "\n",
      "\n",
      "Epoch 174  ;Total Train correct: 2024  ;Train loss: 75.52466252446175\n",
      "Total Validation correct: 419  ;Validation Loss: 20.97050380706787\n",
      "Test Accuracy of the model : 48.52459016393443 %\n",
      "\n",
      "\n",
      "Epoch 175  ;Total Train correct: 1622  ;Train loss: 93.9954959154129\n",
      "Total Validation correct: 469  ;Validation Loss: 22.416670203208923\n",
      "Test Accuracy of the model : 51.256830601092894 %\n",
      "\n",
      "\n",
      "Epoch 176  ;Total Train correct: 1827  ;Train loss: 78.80080550909042\n",
      "Total Validation correct: 465  ;Validation Loss: 19.214733958244324\n",
      "Test Accuracy of the model : 51.038251366120214 %\n",
      "\n",
      "\n",
      "Epoch 177  ;Total Train correct: 1957  ;Train loss: 74.10835242271423\n",
      "Total Validation correct: 502  ;Validation Loss: 20.10437774658203\n",
      "Test Accuracy of the model : 51.91256830601093 %\n",
      "\n",
      "\n",
      "Epoch 178  ;Total Train correct: 1999  ;Train loss: 72.24545884132385\n",
      "Total Validation correct: 446  ;Validation Loss: 18.03120183944702\n",
      "Test Accuracy of the model : 49.39890710382514 %\n",
      "\n",
      "\n",
      "Epoch 179  ;Total Train correct: 1829  ;Train loss: 72.64504688978195\n",
      "Total Validation correct: 454  ;Validation Loss: 18.663596212863922\n",
      "Test Accuracy of the model : 50.05464480874316 %\n",
      "\n",
      "\n",
      "Epoch 180  ;Total Train correct: 1902  ;Train loss: 69.85029554367065\n",
      "Total Validation correct: 500  ;Validation Loss: 18.38967740535736\n",
      "Test Accuracy of the model : 56.6120218579235 %\n",
      "\n",
      "\n",
      "Epoch 181  ;Total Train correct: 1975  ;Train loss: 70.30966597795486\n",
      "Total Validation correct: 475  ;Validation Loss: 18.96548056602478\n",
      "Test Accuracy of the model : 50.38251366120219 %\n",
      "\n",
      "\n",
      "Epoch 182  ;Total Train correct: 2022  ;Train loss: 69.83314806222916\n",
      "Total Validation correct: 509  ;Validation Loss: 17.95731484889984\n",
      "Test Accuracy of the model : 53.98907103825137 %\n",
      "\n",
      "\n",
      "Epoch 183  ;Total Train correct: 1905  ;Train loss: 76.12428373098373\n",
      "Total Validation correct: 412  ;Validation Loss: 28.55844271183014\n",
      "Test Accuracy of the model : 44.15300546448088 %\n",
      "\n",
      "\n",
      "Epoch 184  ;Total Train correct: 1593  ;Train loss: 91.19999647140503\n",
      "Total Validation correct: 347  ;Validation Loss: 24.25607717037201\n",
      "Test Accuracy of the model : 38.5792349726776 %\n",
      "\n",
      "\n",
      "Epoch 185  ;Total Train correct: 1552  ;Train loss: 91.84191644191742\n",
      "Total Validation correct: 380  ;Validation Loss: 24.765733242034912\n",
      "Test Accuracy of the model : 41.202185792349724 %\n",
      "\n",
      "\n",
      "Epoch 186  ;Total Train correct: 1725  ;Train loss: 87.89729762077332\n",
      "Total Validation correct: 410  ;Validation Loss: 24.21132206916809\n",
      "Test Accuracy of the model : 42.404371584699454 %\n",
      "\n",
      "\n",
      "Epoch 187  ;Total Train correct: 1674  ;Train loss: 90.96605086326599\n",
      "Total Validation correct: 343  ;Validation Loss: 29.64506494998932\n",
      "Test Accuracy of the model : 38.0327868852459 %\n",
      "\n",
      "\n",
      "Epoch 188  ;Total Train correct: 1480  ;Train loss: 103.01171457767487\n",
      "Total Validation correct: 388  ;Validation Loss: 25.37540030479431\n",
      "Test Accuracy of the model : 40.98360655737705 %\n",
      "\n",
      "\n",
      "Epoch 189  ;Total Train correct: 1661  ;Train loss: 94.73775553703308\n",
      "Total Validation correct: 352  ;Validation Loss: 27.18169331550598\n",
      "Test Accuracy of the model : 34.6448087431694 %\n",
      "\n",
      "\n",
      "Epoch 190  ;Total Train correct: 1475  ;Train loss: 101.35932147502899\n",
      "Total Validation correct: 381  ;Validation Loss: 26.183727145195007\n",
      "Test Accuracy of the model : 44.80874316939891 %\n",
      "\n",
      "\n",
      "Epoch 191  ;Total Train correct: 1609  ;Train loss: 93.66655206680298\n",
      "Total Validation correct: 402  ;Validation Loss: 23.952871322631836\n",
      "Test Accuracy of the model : 45.13661202185793 %\n",
      "\n",
      "\n",
      "Epoch 192  ;Total Train correct: 1567  ;Train loss: 94.91472387313843\n",
      "Total Validation correct: 400  ;Validation Loss: 23.76133406162262\n",
      "Test Accuracy of the model : 46.22950819672131 %\n",
      "\n",
      "\n",
      "Epoch 193  ;Total Train correct: 1559  ;Train loss: 92.76998198032379\n",
      "Total Validation correct: 407  ;Validation Loss: 23.147880911827087\n",
      "Test Accuracy of the model : 47.759562841530055 %\n",
      "\n",
      "\n",
      "Epoch 194  ;Total Train correct: 1653  ;Train loss: 89.2508202791214\n",
      "Total Validation correct: 416  ;Validation Loss: 22.822984218597412\n",
      "Test Accuracy of the model : 51.147540983606554 %\n",
      "\n",
      "\n",
      "Epoch 195  ;Total Train correct: 1624  ;Train loss: 89.5288952589035\n",
      "Total Validation correct: 427  ;Validation Loss: 22.986891388893127\n",
      "Test Accuracy of the model : 44.69945355191257 %\n",
      "\n",
      "\n",
      "Epoch 196  ;Total Train correct: 1628  ;Train loss: 90.80040431022644\n",
      "Total Validation correct: 432  ;Validation Loss: 23.058584690093994\n",
      "Test Accuracy of the model : 46.557377049180324 %\n",
      "\n",
      "\n",
      "Epoch 197  ;Total Train correct: 1584  ;Train loss: 89.87991678714752\n",
      "Total Validation correct: 413  ;Validation Loss: 22.9234961271286\n",
      "Test Accuracy of the model : 49.2896174863388 %\n",
      "\n",
      "\n",
      "Epoch 198  ;Total Train correct: 1678  ;Train loss: 85.5524805188179\n",
      "Total Validation correct: 431  ;Validation Loss: 22.076232433319092\n",
      "Test Accuracy of the model : 45.57377049180328 %\n",
      "\n",
      "\n",
      "Epoch 199  ;Total Train correct: 1697  ;Train loss: 87.77360916137695\n",
      "Total Validation correct: 396  ;Validation Loss: 23.540070295333862\n",
      "Test Accuracy of the model : 43.169398907103826 %\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim= 1).eq(labels).sum().item()\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "for epoch in range(200):\n",
    "    \n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    \n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "\n",
    "    #####TRAIN DATA SET#####\n",
    "    network.train()\n",
    "    for batch in train_loader: # Get Batch\n",
    "  \n",
    "        labels, images = batch\n",
    "\n",
    "        images = images.view(-1, 1, 3600).type(torch.cuda.FloatTensor)\n",
    "        network.zero_grad()\n",
    "\n",
    "        preds = network(images) # Pass Batch\n",
    "        labels = labels.type(torch.cuda.LongTensor)\n",
    "#         print(labels)\n",
    "#         print(preds)\n",
    "        loss = nn.CrossEntropyLoss()(preds, labels) # Calculate Loss\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update Weights\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_correct += get_num_correct(preds, labels)\n",
    "        \n",
    "\n",
    "        \n",
    "    #####Validation DATA SET#####\n",
    "    \n",
    "    for batch in valid_loader: # Get Batch\n",
    "\n",
    "        labels, images = batch\n",
    "        images = images.view(-1, 1, 3600).type(torch.cuda.FloatTensor)\n",
    "        network.zero_grad()\n",
    "        preds = network(images) # Pass Batch\n",
    "        labels = labels.type(torch.cuda.LongTensor)\n",
    "        loss = nn.CrossEntropyLoss()(preds, labels) # Calculate Loss\n",
    "    \n",
    "#         optimizer.zero_grad()\n",
    "        loss.backward() # Calculate Gradients\n",
    "        optimizer.step() # Update Weights\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        val_correct += get_num_correct(preds, labels)\n",
    "        \n",
    "    print(\"Epoch\", epoch, \" ;Total Train correct:\", train_correct, \" ;Train loss:\", train_loss)\n",
    "    print(\"Total Validation correct:\", val_correct ,\" ;Validation Loss:\", val_loss)\n",
    "    \n",
    "    \n",
    "    # save model if validation loss has decreased\n",
    "    if val_loss <= valid_loss_min:\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "        valid_loss_min,\n",
    "        val_loss))\n",
    "        checkpoint = {'model': network,\n",
    "              'state_dict': network.state_dict(),\n",
    "              'optimizer' : optimizer.state_dict()}\n",
    "\n",
    "        torch.save(checkpoint, 'NewDeep_Attentive_BiModel_99.89.pth')\n",
    "        valid_loss_min = val_loss\n",
    "    \n",
    "    \n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        correct_all = 0\n",
    "        total_all = 0\n",
    "        for labels, images in test_loader:\n",
    "            #             print(images.shape)\n",
    "#             print(labels.shape)\n",
    "            images = images.view(-1,1,3600).type(torch.cuda.FloatTensor)\n",
    "            labels = labels.type(torch.cuda.FloatTensor)\n",
    "#             print(labels.size(0))\n",
    "            preds = network(images)\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            \n",
    "            for i in range(labels.size(0)):\n",
    "                act_label = labels[i] # act_label = 1 (index)\n",
    "                pred_label = torch.argmax(preds[i]) # pred_label = 1 (index)\n",
    "                \n",
    "#                 print(act_label)\n",
    "#                 print(pred_label)\n",
    "                if(act_label == pred_label):\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "            total_all += total\n",
    "            correct_all += correct\n",
    "#         print(correct_all)\n",
    "#         print(total_all)\n",
    "        print('Test Accuracy of the model : {} %'.format(100*(correct_all/total_all))) \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CnnBiLSTM1D(\n",
      "  (tanh): Tanh()\n",
      "  (relu): ReLU()\n",
      "  (dropout_): Dropout(p=0.005, inplace=False)\n",
      "  (softmax): Softmax(dim=1)\n",
      "  (block_1): InitConv(\n",
      "    (relu): ReLU()\n",
      "    (dropout_): Dropout(p=0.005, inplace=False)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (tanh): Tanh()\n",
      "    (softmax): Softmax(dim=1)\n",
      "    (conv1d_1): Conv1d(1, 4, kernel_size=(5,), stride=(2,))\n",
      "    (batch_norm_1d_1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv1d_2): Conv1d(4, 16, kernel_size=(4,), stride=(2,))\n",
      "    (batch_norm_1d_2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv1d_3): Conv1d(16, 32, kernel_size=(4,), stride=(2,))\n",
      "    (batch_norm_1d_3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv1d_4): Conv1d(32, 32, kernel_size=(4,), stride=(2,))\n",
      "    (batch_norm_1d_4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (linear_1d_1): Linear(in_features=7136, out_features=2048, bias=True)\n",
      "    (linear_1d_2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (linear_1d_3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (linear_1d_4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (attention_linear_1d_1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (block_2): InitConv(\n",
      "    (relu): ReLU()\n",
      "    (dropout_): Dropout(p=0.005, inplace=False)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (tanh): Tanh()\n",
      "    (softmax): Softmax(dim=1)\n",
      "    (conv1d_1): Conv1d(1, 4, kernel_size=(5,), stride=(2,))\n",
      "    (batch_norm_1d_1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv1d_2): Conv1d(4, 16, kernel_size=(4,), stride=(2,))\n",
      "    (batch_norm_1d_2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv1d_3): Conv1d(16, 32, kernel_size=(4,), stride=(2,))\n",
      "    (batch_norm_1d_3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv1d_4): Conv1d(32, 32, kernel_size=(4,), stride=(2,))\n",
      "    (batch_norm_1d_4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (linear_1d_1): Linear(in_features=7136, out_features=2048, bias=True)\n",
      "    (linear_1d_2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (linear_1d_3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (linear_1d_4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (attention_linear_1d_1): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (bilinear): Bilinear(in1_features=256, in2_features=256, out_features=256, bias=True)\n",
      "  (linear_1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (linear_2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (linear_3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (linear_4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (out): Linear(in_features=64, out_features=17, bias=True)\n",
      "  (conv_1d_1): Conv1d(1, 8, kernel_size=(4,), stride=(2,))\n",
      "  (batch_norm_1d_1): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bi_lstm_1): LSTM(256, 512, num_layers=2, dropout=0.005, bidirectional=True)\n",
      "  (bi_lstm_2): LSTM(1024, 1024, num_layers=2, dropout=0.002, bidirectional=True)\n",
      ")\n",
      "Test Loss: 0.102077\n",
      "\n",
      "Test Accuracy of     0: 100.000000% (52/52)\n",
      "Test Accuracy of     1: 100.000000% (51/51)\n",
      "Test Accuracy of     2: 92.307692% (36/39)\n",
      "Test Accuracy of     3: 94.642857% (53/56)\n",
      "Test Accuracy of     4: 100.000000% (62/62)\n",
      "Test Accuracy of     5: 96.296296% (52/54)\n",
      "Test Accuracy of     6: 91.836735% (45/49)\n",
      "Test Accuracy of     7: 98.360656% (60/61)\n",
      "Test Accuracy of     8: 100.000000% (61/61)\n",
      "Test Accuracy of     9: 98.000000% (49/50)\n",
      "Test Accuracy of    10: 98.305085% (58/59)\n",
      "Test Accuracy of    11: 100.000000% (59/59)\n",
      "Test Accuracy of    12: 100.000000% (44/44)\n",
      "Test Accuracy of    13: 100.000000% (47/47)\n",
      "Test Accuracy of    14: 98.039216% (50/51)\n",
      "Test Accuracy of    15: 98.214286% (55/56)\n",
      "Test Accuracy of    16: 98.437500% (63/64)\n",
      "\n",
      "Test Accuracy (Overall): 98.032787% (897/915)\n"
     ]
    }
   ],
   "source": [
    "def load_checkpoint(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "    model = checkpoint['model']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    for parameter in model.parameters():\n",
    "        parameter.requires_grad = False\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    return model\n",
    "\n",
    "network_best = load_checkpoint('./NewDeep_Attentive_BiModel_99.89')\n",
    "network_best= network_best.cuda()\n",
    "print(network_best)\n",
    "\n",
    "\n",
    "# accuracy_train= (train_correct/len(train))*100\n",
    "# print('Train Accuracy=' + str(accuracy_train) + '%')\n",
    "\n",
    "\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(20))\n",
    "class_total = list(0. for i in range(20))\n",
    "\n",
    "network_best.eval() # prep model for evaluation\n",
    "\n",
    "for target, data in test_loader:\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    data = data.view(-1, 1, 3600).type(torch.cuda.FloatTensor)\n",
    "    output = network_best(data)\n",
    "    # calculate the loss\n",
    "    loss = F.cross_entropy(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # compare predictions to true label\n",
    "\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(len(target)):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss/len(test_loader.sampler)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(20):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %.6f%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %.6f%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
